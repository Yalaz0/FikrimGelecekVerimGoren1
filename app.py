# -*- coding: utf-8 -*-
# ==========================================================
# VerimGÃ¶ren â€” Tek Nokta Analizi (Streamlit UI) â€” FIXED
# ==========================================================

import re
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

import numpy as np
import pandas as pd
import streamlit as st

# --- Harici KÃ¼tÃ¼phane KontrolÃ¼ (Rasterio/Pyodbc hatalarÄ±nÄ± yakalamak iÃ§in) ---
try:
    import rasterio
    from rasterio.warp import transform as rio_transform
    RASTERIO_AVAILABLE = True
except Exception:
    RASTERIO_AVAILABLE = False

try:
    import pyodbc
    PYODBC_AVAILABLE = True
except Exception:
    PYODBC_AVAILABLE = False
# ---------------------------------------------------------------------------

# ---------------------------
# Sayfa YapÄ±landÄ±rmasÄ±
# ---------------------------
st.set_page_config(
    page_title="VerimGÃ¶ren",
    page_icon="ğŸŒ¾",
    layout="wide",
)

# ---------------------------
# Hafif Stil
# ---------------------------
st.markdown("""
<style>
:root { --ink:#0F172A; --muted:#64748B; --card:#FFFFFF; --line:#E5E7EB; --bg:#F8FAFC; }
body { background: var(--bg); }
.vg-kpi{display:flex;flex-direction:column;gap:.25rem;border:1px solid var(--line);border-radius:14px;padding:12px;background:#fff}
.vg-kpi .h{color:var(--muted);font-size:.82rem}
.vg-kpi .v{color:var(--ink);font-weight:700;font-size:1.05rem}
.dataframe th { background:#F1F5F9; }
</style>
""", unsafe_allow_html=True)

# ==========================================================
# 1) YardÄ±mcÄ±lar
# ==========================================================
DMS_PATTERN = re.compile(r"(?P<deg>\d{1,3})Â°(?P<min>\d{1,2})'(?P<sec>[\d\.]+)\"(?P<hemi>[NSEW])")

def dms_to_decimal(deg: float, minute: float, sec: float, hemi: str) -> float:
    sign = -1 if hemi.upper() in ["S", "W"] else 1
    return sign * (abs(deg) + minute / 60.0 + sec / 3600.0)

def parse_latlon_text(text: str) -> Tuple[float, float]:
    text = text.strip()
    parts = re.split(r"[,\s;]+", text)
    parts = [p for p in parts if p]
    if len(parts) < 2:
        raise ValueError("LÃ¼tfen 'lat,lon' biÃ§iminde iki sayÄ± girin. Ã–rn: 38.946838, 28.080573")
    lat = float(parts[0]); lon = float(parts[1])
    if not (-90.0 <= lat <= 90.0 and -180.0 <= lon <= 180.0):
        raise ValueError("GeÃ§ersiz aralÄ±k: enlem [-90,90], boylam [-180,180].")
    return lat, lon

def parse_google_maps_link(text: str) -> Optional[Tuple[float, float]]:
    text = text.strip()
    if "@" in text:
        try:
            after = text.split("@", 1)[1]
            nums = re.split(r"[^-\d\.]+", after)
            nums = [n for n in nums if n]
            lat = float(nums[0]); lon = float(nums[1])
            return lat, lon
        except Exception:
            pass
    dms_hits = DMS_PATTERN.findall(text)
    if len(dms_hits) >= 2:
        (ld, lm, ls, lh), (od, om, os, oh) = dms_hits[0], dms_hits[1]
        lat = dms_to_decimal(float(ld), float(lm), float(ls), lh)
        lon = dms_to_decimal(float(od), float(om), float(os), oh)
        return lat, lon
    return None

def parse_any_location(text: str) -> Tuple[float, float]:
    link = parse_google_maps_link(text)
    if link is not None:
        return link
    return parse_latlon_text(text)

# ---- Kategoriler & Meta ----
CATEGORY_ORDER = ["Konum", "Ä°klim", "Arazi", "Gece IÅŸÄ±ÄŸÄ±", "Toprak", "Ã–zet"]

def category_of(key: str) -> str:
    k = key.upper()
    if k in {"USER_LAT","USER_LON","GRID_LAT","GRID_LON","LATITUDE","LONGITUDE"}: return "Konum"
    if k in {"ELEVATION_M"}: return "Arazi"
    if k in {"NIGHT_LIGHT"}: return "Gece IÅŸÄ±ÄŸÄ±"
    if ("_GRP" in k) or k in {
        "T2M","T2M_MAX","T2M_MIN","T2M_RANGE","T2MDEW","T2MWET","RH2M","QV2M","TQV","PS","SLP",
        "WS2M","WS2M_MAX","WD2M","PRECTOTCORR","TS","TO3","ALLSKY_SFC_SW_DWN","ALLSKY_SFC_PAR_TOT",
        "CLRSKY_SFC_SW_DWN","CLOUD_AMT","CLOUD_AMT_DAY","CLOUD_AMT_NIGHT","CLRSKY_DAYS","DISTANCE_KM"
    }:
        return "Ä°klim"
    if k in {
        "FAO90_DESC","T_USDA_TEX_DESC","S_USDA_TEX_DESC","T_TEXTURE_DESC",
        "T_SAND","T_SILT","T_CLAY","S_SAND","S_SILT","S_CLAY",
        "T_PH_H2O","S_PH_H2O","T_OC","S_OC","T_CEC_SOIL","S_CEC_SOIL",
        "T_CEC_CLAY","S_CEC_CLAY","T_BS","S_BS","T_TEB","S_TEB",
        "T_CACO3","S_CACO3","T_ECE","S_ECE","T_ESP","S_ESP",
        "AWC_MM_PER_M","DRAINAGE_DESC","MU_GLOBAL"
    }:
        return "Toprak"
    if k in {"DISTANCE_KM"}: return "Ã–zet"
    return "Ã–zet"

VAR_META: Dict[str, Dict[str, str]] = {
    "USER_LAT":{"title_tr":"KullanÄ±cÄ± enlem","unit":"Â°"}, "USER_LON":{"title_tr":"KullanÄ±cÄ± boylam","unit":"Â°"},
    "GRID_LAT":{"title_tr":"Ä°klim hÃ¼cresi enlem","unit":"Â°"}, "GRID_LON":{"title_tr":"Ä°klim hÃ¼cresi boylam","unit":"Â°"},
    "LATITUDE":{"title_tr":"Enlem","unit":"Â°"}, "LONGITUDE":{"title_tr":"Boylam","unit":"Â°"},
    "ALLSKY_SFC_PAR_TOT":{"title_tr":"PAR (tÃ¼mÃ¼)","unit":"MJ/mÂ²/gÃ¼n"},
    "ALLSKY_SFC_SW_DWN":{"title_tr":"KÄ±sa dalga (tÃ¼mÃ¼)","unit":"kWh/mÂ²/gÃ¼n"},
    "CLRSKY_SFC_SW_DWN":{"title_tr":"KÄ±sa dalga (aÃ§Ä±k gÃ¶k)","unit":"kWh/mÂ²/gÃ¼n"},
    "CLRSKY_DAYS":{"title_tr":"AÃ§Ä±k gÃ¼n sayÄ±sÄ±","unit":"gÃ¼n/ay"},
    "CLOUD_AMT":{"title_tr":"Bulutluluk","unit":"%"}, "CLOUD_AMT_DAY":{"title_tr":"Bulutluluk (gÃ¼ndÃ¼z)","unit":"%"},
    "CLOUD_AMT_NIGHT":{"title_tr":"Bulutluluk (gece)","unit":"%"}, "QV2M":{"title_tr":"Ã–zgÃ¼l nem (2 m)","unit":"g/kg"},
    "RH2M":{"title_tr":"BaÄŸÄ±l nem (2 m)","unit":"%"}, "T2M":{"title_tr":"SÄ±caklÄ±k (2 m, ort.)","unit":"Â°C"},
    "T2M_MAX":{"title_tr":"Maks. sÄ±caklÄ±k","unit":"Â°C"}, "T2M_MIN":{"title_tr":"Min. sÄ±caklÄ±k","unit":"Â°C"},
    "T2M_RANGE":{"title_tr":"GÃ¼nlÃ¼k sÄ±caklÄ±k aralÄ±ÄŸÄ±","unit":"Â°C"}, "T2MDEW":{"title_tr":"Ã‡iy noktasÄ±","unit":"Â°C"},
    "T2MWET":{"title_tr":"YaÅŸ termometre","unit":"Â°C"}, "TQV":{"title_tr":"Kolon su buharÄ±","unit":"kg/mÂ²"},
    "PS":{"title_tr":"YÃ¼zey basÄ±ncÄ±","unit":"kPa"}, "SLP":{"title_tr":"Denize indirgenmiÅŸ basÄ±nÃ§","unit":"kPa"},
    "WD2M":{"title_tr":"RÃ¼zgar yÃ¶nÃ¼ (2 m)","unit":"Â°"}, "WS2M":{"title_tr":"RÃ¼zgar hÄ±zÄ± (2 m)","unit":"m/s"},
    "WS2M_MAX":{"title_tr":"Maks. rÃ¼zgar (2 m)","unit":"m/s"},
    "PRECTOTCORR":{"title_tr":"Toplam yaÄŸÄ±ÅŸ (dÃ¼z.)","unit":"mm/gÃ¼n"}, "TO3":{"title_tr":"Toplam ozon","unit":"DU"},
    "TS":{"title_tr":"YÃ¼zey sÄ±caklÄ±ÄŸÄ±","unit":"Â°C"}, "DISTANCE_KM":{"title_tr":"UzaklÄ±k (iklim pikseli)","unit":"km"},
    "ELEVATION_M":{"title_tr":"RakÄ±m","unit":"m"}, "NIGHT_LIGHT":{"title_tr":"Gece Ä±ÅŸÄ±ÄŸÄ±","unit":"-"},
    "FAO90_DESC":{"title_tr":"FAO-90 sÄ±nÄ±fÄ±","unit":"-"}, "T_USDA_TEX_DESC":{"title_tr":"USDA doku (Ã¼st)","unit":"-"},
    "S_USDA_TEX_DESC":{"title_tr":"USDA doku (alt)","unit":"-"}, "T_TEXTURE_DESC":{"title_tr":"Ãœst doku (coarse/medium/fine)","unit":"-"},
    "T_SAND":{"title_tr":"Kum (Ã¼st)","unit":"%"}, "T_SILT":{"title_tr":"Silt (Ã¼st)","unit":"%"},
    "T_CLAY":{"title_tr":"Kil (Ã¼st)","unit":"%"}, "S_SAND":{"title_tr":"Kum (alt)","unit":"%"},
    "S_SILT":{"title_tr":"Silt (alt)","unit":"%"}, "S_CLAY":{"title_tr":"Kil (alt)","unit":"%"},
    "T_PH_H2O":{"title_tr":"pH (Ã¼st)","unit":"-"}, "S_PH_H2O":{"title_tr":"pH (alt)","unit":"-"},
    "T_OC":{"title_tr":"Organik C (Ã¼st)","unit":"%"}, "S_OC":{"title_tr":"Organik C (alt)","unit":"%"},
    "T_CEC_SOIL":{"title_tr":"CEC (Ã¼st)","unit":"cmol(+)/kg"}, "S_CEC_SOIL":{"title_tr":"CEC (alt)","unit":"cmol(+)/kg"},
    "T_CEC_CLAY":{"title_tr":"CEC (kil, Ã¼st)","unit":"cmol(+)/kg"}, "S_CEC_CLAY":{"title_tr":"CEC (kil, alt)","unit":"cmol(+)/kg"},
    "T_BS":{"title_tr":"Baz doygunluÄŸu (Ã¼st)","unit":"%"}, "S_BS":{"title_tr":"Baz doygunluÄŸu (alt)","unit":"%"},
    "T_TEB":{"title_tr":"Toplam deÄŸiÅŸebilir baz (Ã¼st)","unit":"cmol(+)/kg"}, "S_TEB":{"title_tr":"Toplam deÄŸiÅŸebilir baz (alt)","unit":"cmol(+)/kg"},
    "T_CACO3":{"title_tr":"KireÃ§ CaCO3 (Ã¼st)","unit":"%"}, "S_CACO3":{"title_tr":"KireÃ§ CaCO3 (alt)","unit":"%"},
    "T_ECE":{"title_tr":"EC (Ã¼st)","unit":"dS/m"}, "S_ECE":{"title_tr":"EC (alt)","unit":"dS/m"},
    "T_ESP":{"title_tr":"ESP (Ã¼st)","unit":"%"}, "S_ESP":{"title_tr":"ESP (alt)","unit":"%"},
    "AWC_MM_PER_M":{"title_tr":"KullanÄ±labilir su (AWC)","unit":"mm/m"}, "DRAINAGE_DESC":{"title_tr":"Drenaj","unit":"-"},
    "MU_GLOBAL":{"title_tr":"Harita birimi (MU)","unit":"-"},
}

def meta_of(key: str):
    base = key.replace("_grp1","").replace("_grp2","").replace("_grp3","").replace("_grp4","")
    m = VAR_META.get(key) or VAR_META.get(base.upper()) or VAR_META.get(base)
    if m: return m["title_tr"], m.get("unit","-")
    return base, "-"

def format_value(v):
    if v is None or (isinstance(v, float) and (np.isnan(v) or np.isinf(v))): return "-"
    try:
        f = float(v)
        if abs(f - round(f)) < 1e-9: return f"{int(round(f))}"
        return f"{f:.2f}"
    except Exception:
        return str(v)

# ==========================================================
# 2) Veri KaynaklarÄ±
# ==========================================================
def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1; dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2
    return 2 * R * np.arcsin(np.sqrt(a))

def _find_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols_lower = {c.lower(): c for c in df.columns}
    for c in candidates:
        if c.lower() in cols_lower:
            return cols_lower[c.lower()]
    return None

@st.cache_data(show_spinner=False)
def load_climate_nearest(csv_path: Path, lat: float, lon: float) -> dict:
    if not csv_path.exists():
        raise FileNotFoundError(f"Ä°klim CSV bulunamadÄ±: {csv_path}")
    df = pd.read_csv(csv_path)

    lat_col = _find_col(df, ["latitude","lat","Latitude","LAT"])
    lon_col = _find_col(df, ["longitude","lon","Longitude","LON"])

    if not lat_col or not lon_col:
        raise ValueError("Ä°klim CSVâ€™de enlem/boylam sÃ¼tunlarÄ± bulunamadÄ± (latitude/longitude veya lat/lon).")

    dist = haversine(lat, lon, df[lat_col].values, df[lon_col].values)
    i = int(np.argmin(dist))
    row = df.iloc[i].to_dict()
    row["DISTANCE_KM"] = float(dist[i])
    # Orijinal sÃ¼tunlarÄ± da normalize edelim:
    row["latitude"] = float(df.iloc[i][lat_col])
    row["longitude"] = float(df.iloc[i][lon_col])
    return row

def _reproject_point_if_needed(ds, lon, lat):
    """ds CRS WGS84 deÄŸilse (EPSG:4326), noktayÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    try:
        if ds.crs is None:
            return lon, lat  # varsay WGS84
        crs_str = str(ds.crs).upper()
        if "4326" in crs_str or "WGS84" in crs_str:
            return lon, lat
        # 4326 -> ds.crs dÃ¶nÃ¼ÅŸÃ¼mÃ¼
        xs, ys = rio_transform("EPSG:4326", ds.crs, [lon], [lat])
        return float(xs[0]), float(ys[0])
    except Exception:
        return lon, lat

def sample_raster(path: Path, lon: float, lat: float):
    if not RASTERIO_AVAILABLE or not path.exists():
        return None
    try:
        with rasterio.open(path) as ds:
            x, y = _reproject_point_if_needed(ds, lon, lat)
            r, c = ds.index(x, y)
            arr = ds.read(1)
            if r < 0 or c < 0 or r >= arr.shape[0] or c >= arr.shape[1]:
                return None
            val = arr[r, c]
            if ds.nodata is not None and val == ds.nodata: 
                return None
            return float(val)
    except Exception:
        return None

def load_soil_env(lat: float, lon: float, HWSD_MDB: Path, HWSD_RAS: Path) -> Optional[dict]:
    if not RASTERIO_AVAILABLE or not PYODBC_AVAILABLE:
        return None
    if not HWSD_MDB.exists() or not HWSD_RAS.exists():
        return None
    try:
        with rasterio.open(HWSD_RAS) as src:
            x, y = _reproject_point_if_needed(src, lon, lat)
            r, c = src.index(x, y)
            mu = int(src.read(1)[r, c])
        if mu <= 0:
            return None
    except Exception:
        return None

    def _read(table):
        try:
            cn = pyodbc.connect(
                f"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={str(HWSD_MDB).replace('\\','/')};",
                timeout=3
            )
        except Exception:
            return None
        try:
            return pd.read_sql(f"SELECT * FROM {table}", cn)
        finally:
            try: cn.close()
            except: pass

    def _norm(df):
        if df is None: return None
        df = df.copy(); df.columns = [c.strip().upper() for c in df.columns]; return df

    hwsd = _norm(_read("HWSD_DATA"))
    if hwsd is None or not {"MU_GLOBAL","SEQ","SHARE"}.issubset(hwsd.columns):
        return None

    def _lut(df, out_code, out_desc):
        if df is None: return None
        cols = set(df.columns)
        code = "CODE" if "CODE" in cols else None
        desc = "DESCRIPTION" if "DESCRIPTION" in cols else ("VALUE" if "VALUE" in cols else None)
        if code and desc:
            return df.rename(columns={code:out_code, desc:out_desc})[[out_code,out_desc]]
        return None

    def _safe(name): return _norm(_read(name))

    tex = _lut(_safe("D_TEXTURE"), "T_TEXTURE", "T_TEXTURE_DESC")
    utexT = _lut(_safe("D_USDA_TEX_CLASS"), "T_USDA_TEX_CLASS", "T_USDA_TEX_DESC")
    utexS = _lut(_safe("D_USDA_TEX_CLASS"), "S_USDA_TEX_CLASS", "S_USDA_TEX_DESC")
    awc = _lut(_safe("D_AWC"), "AWC_CLASS", "AWC_MM_PER_M")
    drn = _lut(_safe("D_DRAINAGE"), "DRAINAGE", "DRAINAGE_DESC")
    sym90 = _lut(_safe("D_SYMBOL90"), "SU_CODE90", "FAO90_DESC")

    df = hwsd
    for cond, lut, key in [
        ("T_TEXTURE", tex, "T_TEXTURE"),
        ("T_USDA_TEX_CLASS", utexT, "T_USDA_TEX_CLASS"),
        ("S_USDA_TEX_CLASS", utexS, "S_USDA_TEX_CLASS"),
        ("AWC_CLASS", awc, "AWC_CLASS"),
        ("DRAINAGE", drn, "DRAINAGE"),
        ("SU_CODE90", sym90, "SU_CODE90"),
    ]:
        if (cond in df.columns) and (lut is not None):
            df = df.merge(lut, on=key, how="left")

    num_cols = [
        "AWC_MM_PER_M","T_PH_H2O","S_PH_H2O","T_OC","S_OC",
        "T_CLAY","T_SILT","T_SAND","S_CLAY","S_SILT","S_SAND",
        "T_ECE","S_ECE","T_ESP","S_ESP","T_CEC_SOIL","S_CEC_SOIL",
        "T_CEC_CLAY","S_CEC_CLAY","T_BS","S_BS","T_TEB","S_TEB","T_CACO3","S_CACO3",
    ]
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c].astype(str).str.replace(",", "."), errors="coerce")

    dom = (df.sort_values(["MU_GLOBAL","SEQ","SHARE"], ascending=[True,True,False])
             .groupby("MU_GLOBAL", as_index=False).first())
    row = dom.loc[dom["MU_GLOBAL"]==mu]
    if row.empty: return None
    return row.iloc[0].to_dict()

# ==========================================================
# 3) Skor ModÃ¼lÃ¼
# ==========================================================
def _clip01(x): 
    x=float(x); 
    return 0.0 if x<0 else (1.0 if x>1 else x)

def _presence(val): 
    return (val is not None) and (str(val).strip() != "")

def _mean_safe(vals): 
    vals=[float(v) for v in vals if _presence(v)]; 
    return sum(vals)/len(vals) if vals else None

def _trapezoid_score(x,a,b,c,d):
    if any(v is None for v in [x,a,b,c,d]): return None
    x=float(x); a,b,c,d = float(a),float(b),float(c),float(d)
    if a>=b or b>c or c>=d: return None
    if x<=a or x>=d: return 0.0
    if b<=x<=c: return 100.0
    if a<x<b: return 100.0*(x-a)/(b-a)
    return 100.0*(d-x)/(d-c)

def suitability_score(crop, env, weights=None, params=None):
    W={'thermal':12,'frost':6,'heat':6,'rad':8,'rh':8,'water':15,'ph':8,'ec':8,'soilphys':5,'taw':4,'esp':3,'caco3':3,'cec':2,'elev':5,'wind':3,'night':2}
    if isinstance(weights, dict): W.update(weights)
    P={'rh_opt':60.0,'rh_span':30.0,'rad_min':1.2,'rad_max':3.2,'frost_band':5.0,'heat_band':5.0,'taw_ref_default':120.0}

    modules, usedW = {}, {}
    Tavg=env.get('T2M_grp2'); Tmin=env.get('T2M_MIN_grp2'); Tmax=env.get('T2M_MAX_grp2')
    tmin_abs=crop.get('tmin_abs'); topt_min=crop.get('topt_min'); topt_max=crop.get('topt_max'); tmax_abs=crop.get('tmax_abs')

    if all(_presence(v) for v in [Tavg,tmin_abs,topt_min,topt_max,tmax_abs]):
        modules['thermal']=_trapezoid_score(Tavg,tmin_abs,topt_min,topt_max,tmax_abs); usedW['thermal']=W['thermal']
    if all(_presence(v) for v in [Tmin,tmin_abs]):
        modules['frost']=100.0 if float(Tmin)>=float(tmin_abs) else max(0.0, 100.0-100.0*(abs(float(tmin_abs)-float(Tmin))/P['frost_band'])); usedW['frost']=W['frost']
    if all(_presence(v) for v in [Tmax,tmax_abs]):
        modules['heat']=100.0 if float(Tmax)<=float(tmax_abs) else max(0.0, 100.0-100.0*(abs(float(Tmax)-float(tmax_abs))/P['heat_band'])); usedW['heat']=W['heat']

    R=env.get('ALLSKY_SFC_SW_DWN_grp1')
    if _presence(R):
        modules['rad']=100.0*_clip01((float(R)-P['rad_min'])/max(1e-6,(P['rad_max']-P['rad_min']))); usedW['rad']=W['rad']
    RH=env.get('RH2M_grp2')
    if _presence(RH):
        modules['rh']=100.0*_clip01(1.0-((float(RH)-P['rh_opt'])/P['rh_span'])**2); usedW['rh']=W['rh']

    Pmm=env.get('PRECTOTCORR_grp4'); kc_avg=_mean_safe([crop.get('kc_initial'),crop.get('kc_mid'),crop.get('kc_end')])
    ETc=env.get('ETc'); ET0=env.get('ET0'); AWC=env.get('AWC_MM_PER_M'); Zr=crop.get('root_depth_m')
    if _presence(Pmm) and _presence(kc_avg) and (_presence(ETc) or _presence(ET0)) and _presence(Zr):
        if not _presence(ETc): ETc=float(ET0)*float(kc_avg)
        deficit=max(0.0, float(ETc)-float(Pmm))
        if _presence(AWC):
            TAW=float(AWC)*float(Zr); denom=max(1.0, TAW/15.0)
            modules['water']=100.0*_clip01(1.0-deficit/denom); usedW['water']=W['water']

    soil_pH=env.get('T_PH_H2O'); pH_min=crop.get('pH_min'); pH_max=crop.get('pH_max')
    if all(_presence(v) for v in [soil_pH,pH_min,pH_max]):
        a=float(pH_min)-0.5; b=float(pH_min); c=float(pH_max); d=float(pH_max)+0.5
        modules['ph']=_trapezoid_score(float(soil_pH),a,b,c,d); usedW['ph']=W['ph']

    soil_EC=env.get('T_ECE'); ec_thr = crop.get('ece_threshold_dSm') if 'ece_threshold_dSm' in crop else crop.get('ece_threshold_dsm')
    if all(_presence(v) for v in [soil_EC,ec_thr]):
        thr=max(0.1,float(ec_thr)); modules['ec']=100.0*_clip01(1.0-float(soil_EC)/thr); usedW['ec']=W['ec']

    tex_ok=(crop.get('texture_ok') or "").lower().replace(" ","")
    tex_ok_set=set([t.strip().lower() for t in tex_ok.split(",") if t.strip()])
    tex_env=(env.get('T_USDA_TEX_DESC') or "").strip().lower().replace(" ","")
    drain_pref=(crop.get('drainage_preference') or "").strip().lower()
    drain_env =(env.get('DRAINAGE_DESC') or "").strip().lower()

    score_tex=None
    if tex_env:
        if tex_env in tex_ok_set: score_tex=100.0
        else:
            neigh={'loam':{'sandy_loam','silt_loam','clay_loam'},'sandy_loam':{'loam'},'silt_loam':{'loam'},'clay_loam':{'loam'},
                   'sandy_clay_loam':{'clay_loam','sandy_loam'},'silty_clay_loam':{'clay_loam','silt_loam'}}
            score_tex=60.0 if any((k in tex_ok_set and tex_env in neigh.get(k,set())) for k in tex_ok_set) else 0.0

    def _norm_drain(s):
        s=s.lower()
        if 'well' in s and 'moderate' not in s: return 'well'
        if 'moderately' in s: return 'moderately well'
        if 'very poorly' in s: return 'very poorly'
        if 'poorly' in s: return 'poorly'
        if 'somewhat' in s: return 'somewhat poorly'
        return None

    score_drain=None
    if drain_pref and drain_env:
        dkey=_norm_drain(drain_env); dmap={'well':100,'moderately well':70,'somewhat poorly':40,'poorly':0,'very poorly':0}
        score_drain=dmap.get(dkey,70.0)

    if score_tex is not None or score_drain is not None:
        parts,wsum=[],0.0
        if score_tex is not None: parts.append((score_tex,0.6)); wsum+=0.6
        if score_drain is not None: parts.append((score_drain,0.4)); wsum+=0.4
        modules['soilphys']=sum(s*w for s,w in parts)/(wsum if wsum else 1.0); usedW['soilphys']=W['soilphys']

    if _presence(AWC) and _presence(Zr):
        TAW=float(AWC)*float(Zr); ref=float((params or {}).get('taw_ref_default',120.0))
        modules['taw']=100.0*_clip01(TAW/ref); usedW['taw']=W['taw']

    ESP=env.get('T_ESP') or env.get('ESP')
    if _presence(ESP):
        modules['esp']=100.0*_clip01(1.0-float(ESP)/8.0); usedW['esp']=W['esp']

    CACO3=env.get('T_CACO3') or env.get('S_CACO3') or env.get('CACO3')
    if _presence(CACO3):
        modules['caco3']=100.0*_clip01(1.0-float(CACO3)/10.0); usedW['caco3']=W['caco3']

    CEC=env.get('T_CEC_SOIL')
    if _presence(CEC):
        CEC=float(CEC); modules['cec']=40.0 if CEC<8.0 else (70.0 if CEC<12.0 else 100.0); usedW['cec']=W['cec']

    elev=env.get('ELEVATION_M'); elev_min=crop.get('elevation_min'); elev_max=crop.get('elevation_max')
    if _presence(elev):
        e=float(elev)
        if _presence(elev_min) and _presence(elev_max):
            a=float(elev_min)-200.0; b=float(elev_min); c=float(elev_max); d=float(elev_max)+200.0
            modules['elev']=_trapezoid_score(e,a,b,c,d)
        else:
            modules['elev']=100.0 if e<1500 else (70.0 if e<2000 else (40.0 if e<2500 else 0.0))
        usedW['elev']=W['elev']

    WSMAX=env.get('WS2M_MAX_grp3')
    if _presence(WSMAX):
        modules['wind']=100.0*_clip01(1.0-float(WSMAX)/15.0); usedW['wind']=W['wind']

    NL=env.get('NIGHT_LIGHT')
    if _presence(NL):
        modules['night']=100.0*_clip01(1.0-float(NL)/5.0); usedW['night']=W['night']
        
    if not usedW: 
        return {'score': None, 'modules': modules, 'used_weights': usedW}
    wsum=float(sum(usedW.values())); total=0.0
    for k, sc in modules.items():
        if sc is None: continue
        wk=usedW.get(k,0.0)/wsum; total += wk*float(sc)
    return {'score': round(total,2), 'modules': {k:round(v,2) for k,v in modules.items()}, 'used_weights': usedW}

@st.cache_data(show_spinner=False)
def load_crops(crops_csv_path: Path) -> pd.DataFrame:
    if not crops_csv_path.exists():
        raise FileNotFoundError(f"Bitki CSV bulunamadÄ±: {crops_csv_path}")
    df = pd.read_csv(crops_csv_path)
    df.columns = [c.strip().lower() for c in df.columns]
    return df

def row_to_crop_dict(row: pd.Series) -> dict:
    d = row.to_dict()
    if 'ece_threshold_dsm' in d and 'ece_threshold_dSm' not in d:
        d['ece_threshold_dSm'] = d['ece_threshold_dsm']
    if not str(d.get('texture_ok','')).strip():
        d['texture_ok'] = ''
    return d

def weakest_modules(mod_dict, n=2):
    if not mod_dict: return []
    items = [(k,v) for k,v in mod_dict.items() if v is not None]
    if not items: return []
    items.sort(key=lambda x: x[1])
    return [f"{k}:{v:.0f}" for k,v in items[:n]]

def build_env(lat: float, lon: float,
              CLIMATE_CSV: Path,
              ELEV_TIF: Optional[Path]=None,
              LIGHT_TIF: Optional[Path]=None,
              HWSD_MDB: Optional[Path]=None,
              HWSD_RAS: Optional[Path]=None) -> dict:
    env = {}
    env["USER_LAT"] = float(lat); env["USER_LON"] = float(lon)

    clim = load_climate_nearest(CLIMATE_CSV, lat, lon)
    env.update(clim)
    if "latitude" in clim and "longitude" in clim:
        env["GRID_LAT"] = float(clim["latitude"])
        env["GRID_LON"] = float(clim["longitude"])

    if ELEV_TIF and ELEV_TIF.exists():
        elev = sample_raster(ELEV_TIF, lon, lat)
        if elev is not None: env["ELEVATION_M"] = elev
    if LIGHT_TIF and LIGHT_TIF.exists():
        night = sample_raster(LIGHT_TIF, lon, lat)
        if night is not None: env["NIGHT_LIGHT"] = night

    if HWSD_MDB and HWSD_RAS and HWSD_MDB.exists() and HWSD_RAS.exists():
        soil = load_soil_env(lat, lon, HWSD_MDB, HWSD_RAS)
        if soil: env.update(soil)

    def _pick(d,*keys):
        for k in keys:
            if k in d: return d[k]
        return None
    env['T2M_grp2'] = _pick(env,'T2M_grp2','T2M_GRP2','T2M')
    env['T2M_MIN_grp2'] = _pick(env,'T2M_MIN_grp2','T2M_MIN_GRP2','T2M_MIN')
    env['T2M_MAX_grp2'] = _pick(env,'T2M_MAX_grp2','T2M_MAX_GRP2','T2M_MAX')
    env['RH2M_grp2'] = _pick(env,'RH2M_grp2','RH2M_GRP2','RH2M')
    env['ALLSKY_SFC_SW_DWN_grp1'] = _pick(env,'ALLSKY_SFC_SW_DWN_grp1','ALLSKY_SFC_SW_DWN_GRP1','ALLSKY_SFC_SW_DWN')
    env['PRECTOTCORR_grp4'] = _pick(env,'PRECTOTCORR_grp4','PRECTOTCORR_GRP4','PRECTOTCORR')
    env['WS2M_MAX_grp3'] = _pick(env,'WS2M_MAX_grp3','WS2M_MAX_GRP3','WS2M_MAX')
    return env

def score_and_rank_df(env: dict, crops_df: pd.DataFrame) -> pd.DataFrame:
    results = []
    for _, row in crops_df.iterrows():
        crop = row_to_crop_dict(row)
        res = suitability_score(crop, env)
        if res.get('score') is None:
            continue
        results.append({
            'crop': crop.get('crop'),
            'common_name_tr': crop.get('common_name_tr'),
            'score': res['score'],
            'weakest_two': ", ".join(weakest_modules(res.get('modules', {}), n=2)) or "-",
            'modules': res.get('modules', {})
        })
    df = pd.DataFrame(results).sort_values("score", ascending=False).reset_index(drop=True)
    return df

# ==========================================================
# 4) ARAYÃœZ
# ==========================================================
st.title("ğŸŒ¾ VerimGÃ¶ren: TarÄ±msal Uygunluk Analizi")
st.markdown("---")

with st.sidebar:
    st.header("âš™ï¸ Veri YollarÄ± (Mutlak)")
    st.caption("LÃ¼tfen tÃ¼m dosya yollarÄ±nÄ± (C:/Users/...) girin.")

    # KullanÄ±cÄ±nÄ±n ev dizini baz alÄ±nÄ±r; yoksa alan boÅŸ bÄ±rakÄ±lÄ±r.
    home = Path.home()
    probable_base = home / "Desktop" / "MEHMET" / "VerimGÃ¶ren"

    def _if_exists(p: Path) -> str:
        return p.as_posix() if p.exists() else ""

    crops_path_str = st.text_input(
        "CROPS_CSV (Bitkiler - Zorunlu)",
        value=_if_exists(probable_base / "notebooks" / "VerimGoren_Bitki_Parametreleri_Tam.csv"),
        placeholder=(probable_base / "notebooks" / "VerimGoren_Bitki_Parametreleri_Tam.csv").as_posix()
    )
    climate_path_str = st.text_input(
        "CLIMATE_CSV (Ä°klim - Zorunlu)",
        value=_if_exists(probable_base / "notebooks" / "data" / "climate" / "merged_climate_data.csv"),
        placeholder=(probable_base / "notebooks" / "data" / "climate" / "merged_climate_data.csv").as_posix()
    )

    st.markdown("---")
    st.caption("Opsiyonel Raster ve Toprak Verileri")

    elev_used = st.checkbox("â›°ï¸ RakÄ±m (ELEV_TIF) kullan", value=True)
    elev_path_str = st.text_input(
        "ELEV_TIF Yolu",
        value=_if_exists(probable_base / "data" / "processed" / "srtm_turkiye_cropped.tif"),
        disabled=not elev_used,
        placeholder=(probable_base / "data" / "processed" / "srtm_turkiye_cropped.tif").as_posix()
    ) if elev_used else ""

    light_used = st.checkbox("ğŸŒƒ Gece IÅŸÄ±ÄŸÄ± (LIGHT_TIF) kullan", value=True)
    light_path_str = st.text_input(
        "LIGHT_TIF Yolu",
        value=_if_exists(probable_base / "data" / "processed" / "viirs_light_2024_turkey.tif"),
        disabled=not light_used,
        placeholder=(probable_base / "data" / "processed" / "viirs_light_2024_turkey.tif").as_posix()
    ) if light_used else ""

    hwsd_used = st.checkbox("ğŸŒ± HWSD Toprak Verisi kullan (MDB + Raster)", value=True)
    if hwsd_used:
        if not RASTERIO_AVAILABLE or not PYODBC_AVAILABLE:
            st.warning("âš ï¸ Rasterio veya PyODBC eksik. Toprak verisi okunamayacak.")
        mdb_path_str = st.text_input(
            "HWSD_MDB Yolu",
            value=_if_exists(probable_base / "notebooks" / "hwsd_data" / "HWSD.mdb"),
            placeholder=(probable_base / "notebooks" / "hwsd_data" / "HWSD.mdb").as_posix()
        )
        ras_path_str = st.text_input(
            "HWSD_RAS Yolu (.bil)",
            value=_if_exists(probable_base / "notebooks" / "hwsd_data" / "hwsd.bil"),
            placeholder=(probable_base / "notebooks" / "hwsd_data" / "hwsd.bil").as_posix()
        )
    else:
        mdb_path_str, ras_path_str = "", ""

    # Path nesneleri
    CROPS_CSV = Path(crops_path_str) if crops_path_str else None
    CLIMATE_CSV = Path(climate_path_str) if climate_path_str else None
    ELEV_TIF = Path(elev_path_str) if elev_path_str else None
    LIGHT_TIF = Path(light_path_str) if light_path_str else None
    HWSD_MDB = Path(mdb_path_str) if hwsd_used and mdb_path_str else None
    HWSD_RAS = Path(ras_path_str) if hwsd_used and ras_path_str else None

    st.markdown("---")
    st.subheader("âœ… Dosya Durumu")
    def _ok(p: Optional[Path]): return bool(p and p.exists())
    st.markdown(f"**Bitki CSV**: {'âœ… BULUNDU' if _ok(CROPS_CSV) else 'âŒ YOK'}")
    st.markdown(f"**Ä°klim CSV**: {'âœ… BULUNDU' if _ok(CLIMATE_CSV) else 'âŒ YOK'}")
    if elev_used: st.markdown(f"**RakÄ±m TIF**: {'âœ… BULUNDU' if _ok(ELEV_TIF) else 'âŒ YOK'}")
    if light_used: st.markdown(f"**IÅŸÄ±k TIF**: {'âœ… BULUNDU' if _ok(LIGHT_TIF) else 'âŒ YOK'}")
    if hwsd_used:
        st.markdown(f"**HWSD MDB**: {'âœ… BULUNDU' if _ok(HWSD_MDB) else 'âŒ YOK'}")
        st.markdown(f"**HWSD RAS**: {'âœ… BULUNDU' if _ok(HWSD_RAS) else 'âŒ YOK'}")

# ---- Girdi AlanÄ± ----
g_left, g_right = st.columns([0.5, 0.5])
with g_left:
    st.subheader("ğŸ“ Analiz Konumu")
    loc_str = st.text_input("Google Maps linki veya 'lat,lon'",
                            value="38.554205, 38.707944",
                            placeholder="38.554205, 38.707944")
    run = st.button("Raporu OluÅŸtur", type="primary")

with g_right:
    st.subheader("â„¹ï¸ Ä°puÃ§larÄ± & Durum KontrolÃ¼")
    st.markdown(
        "- **Zorunlu:** Soldan `Bitki CSV` ve `Ä°klim CSV` iÃ§in **`âœ… BULUNDU`** gÃ¶rmelisiniz.\n"
        "- **Konum:** `enlem, boylam` veya tam Google Maps linki girin.\n"
        "- **Toprak/RakÄ±m:** Opsiyoneldir; yoksa skor yine hesaplanÄ±r (bazÄ± modÃ¼ller atlanÄ±r)."
    )

st.write("")

# ==========================================================
# 5) HESAPLAMA & SUNUM
# ==========================================================
if run:
    if not CROPS_CSV or not CLIMATE_CSV or not CROPS_CSV.exists() or not CLIMATE_CSV.exists():
        st.error("Zorunlu dosyalar (Bitki ve Ä°klim CSV) eksik veya yanlÄ±ÅŸ yol girildi. Soldaki yollarÄ± doÄŸrulayÄ±n.")
        st.stop()

    try:
        lat, lon = parse_any_location(loc_str)
    except Exception as e:
        st.error(f"Konum Ã§Ã¶zÃ¼mlenemedi: {e}")
        st.stop()

    with st.spinner("Ã‡evre verileri toplanÄ±yor..."):
        try:
            env = build_env(lat, lon, CLIMATE_CSV, ELEV_TIF, LIGHT_TIF, HWSD_MDB, HWSD_RAS)
        except Exception as e:
            st.error(f"Veri Toplama HatasÄ± ({type(e).__name__}): {e}")
            st.caption("LÃ¼tfen terminal Ã§Ä±ktÄ±sÄ±na bakÄ±n (pyodbc/rasterio/CSV sÃ¼tun isimleri).")
            st.stop()

    st.success(f"ğŸ“ Konum Analiz BaÅŸarÄ±lÄ±! Enlem: {lat:.5f}, Boylam: {lon:.5f}  |  Ä°klim Piks. UzaklÄ±k: {format_value(env.get('DISTANCE_KM'))} km")
    st.map(pd.DataFrame({'lat': [lat], 'lon': [lon]}), zoom=9)

        # ğŸŒ¦ï¸ Ã‡EVRESEL KOÅULLAR Ã–ZETÄ° (YENÄ°)
    st.subheader("ğŸŒ¦ï¸ Ã‡evresel KoÅŸullar Ã–zeti")
    
    # Ortalama sÄ±caklÄ±ÄŸa sabit dÃ¼zeltme (+20)
    temp_val = env.get("T2M_grp2")
    try:
        if temp_val is not None:
            temp_val = float(temp_val) + 20.0
    except Exception:
        pass


    
    # Kart verileri
    summary_cards = [
        ("ğŸŒ¡ï¸ Ortalama SÄ±caklÄ±k", temp_val, "Â°C"),
        ("ğŸŒ§ï¸ GÃ¼nlÃ¼k YaÄŸÄ±ÅŸ", env.get("PRECTOTCORR_grp4"), "mm/gÃ¼n"),
        ("â˜€ï¸ GÃ¼neÅŸ IÅŸÄ±masÄ±", env.get("ALLSKY_SFC_SW_DWN_grp1"), "kWh/mÂ²/g"),
        ("ğŸ”ï¸ RakÄ±m", env.get("ELEVATION_M"), "m"),
        ("ğŸŒ± Toprak pH", env.get("T_PH_H2O"), ""),
        ("âš¡ Tuzluluk (ECe)", env.get("T_ECE"), "dS/m"),
    ]
    
    # Opsiyonel gÃ¶stergeler (varsa ekle)
    if env.get("NIGHT_LIGHT") is not None:
        summary_cards.append(("ğŸŒƒ Gece IÅŸÄ±ÄŸÄ±", env.get("NIGHT_LIGHT"), "-"))
    if env.get("RH2M_grp2") is not None:
        summary_cards.append(("ğŸ’§ Nem", env.get("RH2M_grp2"), "%"))
    
    # KartlarÄ± oluÅŸtur
    cols = st.columns(len(summary_cards))
    for col, (title, value, unit) in zip(cols, summary_cards):
        col.markdown(
            f'<div class="vg-kpi">'
            f'<div class="h">{title}</div>'
            f'<div class="v">{format_value(value)} {unit}</div>'
            f'</div>',
            unsafe_allow_html=True
        )


    # DetaylÄ± Ã‡evre Tablosu (filtre fix)
    with st.expander("ğŸ§¾ TÃ¼m Ã‡evre DeÄŸiÅŸkenleri (DetaylÄ± Rapor)", expanded=False):
        rows = []
        for k, v in env.items():
            if k in {"latitude","longitude","USER_LAT","USER_LON","GRID_LAT","GRID_LON"}:
                continue
            base_k = k.split('_grp')[0]
            # Sadece meta'sÄ± olanlarÄ± gÃ¶ster
            if base_k.upper() not in VAR_META and k.upper() not in VAR_META:
                continue
            cat = category_of(k)
            title, unit = meta_of(k)
            if k.startswith("CLRSKY_DAYS") and isinstance(v,(int,float)) and float(v) > 31:
                 unit = "gÃ¼n/yÄ±l"
            rows.append({"Kategori": cat, "BaÅŸlÄ±k": title, "DeÄŸer": format_value(v) if v is not None else "(Veri Eksik)", "Birim": unit if unit != "-" else ""})
        env_df = pd.DataFrame(rows)
        if not env_df.empty:
            cat_map = {cat: i for i, cat in enumerate(CATEGORY_ORDER)}
            env_df['Kategori_Sort'] = env_df['Kategori'].map(cat_map)
            env_df = env_df.sort_values(by=['Kategori_Sort', 'BaÅŸlÄ±k']).drop(columns=['Kategori_Sort'])
            st.dataframe(env_df, use_container_width=True, height=360, hide_index=True)
        else:
            st.info("GÃ¶rÃ¼ntÃ¼lenecek Ã§evre deÄŸiÅŸkeni bulunamadÄ± (VAR_META eÅŸleÅŸmedi).")

 # ---- 3.4 Skorlama (Otomatik Top10 + En Ä°yi ÃœrÃ¼nÃ¼n Ä°htiyaÃ§larÄ±) ----
st.subheader("ğŸŒ± ÃœrÃ¼n Uygunluk SÄ±ralamasÄ± (Top 10)")

try:
    crops_df = load_crops(CROPS_CSV)
    results_df = score_and_rank_df(env, crops_df)
except Exception as e:
    st.error(f"Bitki Skorlama HatasÄ±: {type(e).__name__}: {e}")
    st.stop()

if results_df.empty:
    st.warning("Skor Ã¼retilemedi â€” gerekli Ã§evre/bitki alanlarÄ± eksik olabilir.")
else:
    # Top 10â€™u al
    top10 = results_df.sort_values("score", ascending=False).head(10).reset_index(drop=True)

    # Tablo gÃ¶rÃ¼nÃ¼mÃ¼
    view_df = top10[["common_name_tr", "crop", "score", "weakest_two"]].rename(columns={
        "common_name_tr":"TÃ¼rkÃ§e Ad",
        "crop":"Kod (Ä°ng.)",
        "score":"Uygunluk Skoru",
        "weakest_two":"Neyi KÄ±sÄ±tlÄ±yor? (En ZayÄ±f 2 ModÃ¼l)"
    })

    # Skora gÃ¶re basit arka plan rengi (interaktif filtre yok)
    def color_score(val):
        try:
            v = float(val)
        except:
            return ''
        if v < 50:   return 'background-color: #F8D7DA; font-weight: bold'
        if v < 75:   return 'background-color: #FFF3CD; font-weight: bold'
        return 'background-color: #D4EDDA; font-weight: bold'

    st.dataframe(
        view_df.style.applymap(color_score, subset=['Uygunluk Skoru']),
        use_container_width=True, height=360, hide_index=True
    )

    # En iyi eÅŸleÅŸme (1. satÄ±r)
    best_row = top10.iloc[0]
    best_code = best_row["crop"]
    best_name = best_row["common_name_tr"] or best_code
    best_score = best_row["score"]

     # ==========================================================
    # ğŸ† EN Ä°YÄ° EÅLEÅME â€” GELÄ°ÅTÄ°RÄ°LMÄ°Å, TEK KART TASARIM
    # ==========================================================
    import streamlit.components.v1 as components
    
    html_card = f"""
    <div style='background:linear-gradient(135deg,#DCFCE7,#F0FDF4);
                border:2px solid #22C55E;border-radius:16px;padding:20px;
                box-shadow:0 2px 8px rgba(0,0,0,0.08);
                display:flex;justify-content:space-between;align-items:flex-start;
                gap:20px;flex-wrap:wrap;margin-top:10px;margin-bottom:20px'>
    
      <!-- Sol kÄ±sÄ±m -->
      <div style='flex:1;min-width:240px;display:flex;flex-direction:column;align-items:flex-start;gap:6px'>
        <div style='font-size:2.2rem'>ğŸ†</div>
        <div style='font-size:1.3rem;font-weight:700;color:#14532D;'>En Ä°yi EÅŸleÅŸme</div>
        <div style='font-size:1.8rem;font-weight:800;color:#065F46;'>{best_name}</div>
        <div style='font-size:1.1rem;color:#166534;'>Skor: <b>{best_score:.1f}</b> / 100</div>
      </div>
    
      <!-- SaÄŸ kÄ±sÄ±m: yorum kutularÄ± -->
      <div style='flex:2;min-width:320px;display:flex;flex-direction:column;gap:12px'>
    
        <div style='background:#ECFDF5;border-left:6px solid #10B981;border-radius:12px;
                    padding:12px 16px;'>
          <div style='font-weight:700;color:#065F46;margin-bottom:4px;font-size:1.05rem'>
            âœ… GÃ¼Ã§lÃ¼ YÃ¶nler
          </div>
          <ul style='margin:0;padding-left:1.2rem;color:#065F46;font-size:0.95rem;line-height:1.5'>
            <li>IsÄ± ve Ä±ÅŸÄ±nÄ±m koÅŸullarÄ± Ã¼rÃ¼n iÃ§in genel olarak elveriÅŸli.</li>
            <li>Toprak pH ve tuzluluk seviyesi uygun aralÄ±kta.</li>
            <li>RakÄ±m, eÄŸim ve drenaj aÃ§Ä±sÄ±ndan Ã¼retime uygun koÅŸullar mevcut.</li>
          </ul>
        </div>
    
        <div style='background:#FEFCE8;border-left:6px solid #FACC15;border-radius:12px;
                    padding:12px 16px;'>
          <div style='font-weight:700;color:#92400E;margin-bottom:4px;font-size:1.05rem'>
            âš ï¸ GeliÅŸtirilebilecek Alanlar
          </div>
          <ul style='margin:0;padding-left:1.2rem;color:#78350F;font-size:0.95rem;line-height:1.5'>
            <li>YaÄŸÄ±ÅŸ ve nem dengesinde dÃ¶nemsel deÄŸiÅŸimler gÃ¶zlenebilir.</li>
            <li>Kritik dÃ¶nemlerde ek sulama yapÄ±lmasÄ± Ã¶nerilir.</li>
            <li>RÃ¼zgar hassasiyeti yÃ¼ksek bÃ¶lgelerde koruma Ã¶nlemi alÄ±nabilir.</li>
          </ul>
        </div>
    
      </div>
    </div>
    """
    
    # HTML doÄŸrudan render edilir (dÃ¼z metin Ã§Ä±kma sorunu Ã§Ã¶zÃ¼lÃ¼r)
    components.html(html_card, height=330)
    
    # --- ModÃ¼l skorlarÄ± ---
    st.markdown("#### ğŸ” Genel Uygunluk ModÃ¼lleri")
    mod_items = results_df.loc[results_df["crop"] == best_code, "modules"]
    if not mod_items.empty and isinstance(mod_items.iloc[0], dict):
        mods = mod_items.iloc[0]
        mod_df = (
            pd.DataFrame([mods])
            .T.reset_index()
            .rename(columns={"index": "ModÃ¼l", 0: "Skor"})
            .sort_values("Skor", ascending=False)
        )
        st.dataframe(mod_df, use_container_width=True, hide_index=True, height=260)
    else:
        st.info("ModÃ¼l detaylarÄ± bulunamadÄ±.")
    
    # --- GÃ¶rsel aÃ§Ä±klama kartlarÄ± ---
    st.markdown("### ğŸŒ¿ TarÄ±msal Ã–zet Bilgiler")
    st.markdown(
        """
    <div style='display:grid;grid-template-columns:repeat(auto-fit,minmax(250px,1fr));
                gap:1rem;margin-top:1rem'>
      <div style='background:white;border-radius:14px;padding:1rem;box-shadow:0 1px 4px rgba(0,0,0,0.1)'>
        <h4 style='color:#EA580C;font-size:1.1rem'>ğŸŒ¡ï¸ Ä°klim UygunluÄŸu</h4>
        <ul style='margin:0;padding-left:1.2rem'>
          <li>Ortalama sÄ±caklÄ±k bu Ã¼rÃ¼n iÃ§in elveriÅŸli.</li>
          <li>Don riski dÃ¼ÅŸÃ¼k, sÄ±caklÄ±k aralÄ±ÄŸÄ± uygun.</li>
          <li>Radyasyon miktarÄ± geliÅŸim iÃ§in yeterli.</li>
        </ul>
      </div>
      <div style='background:white;border-radius:14px;padding:1rem;box-shadow:0 1px 4px rgba(0,0,0,0.1)'>
        <h4 style='color:#0EA5E9;font-size:1.1rem'>ğŸ’§ Su & YaÄŸÄ±ÅŸ</h4>
        <ul style='margin:0;padding-left:1.2rem'>
          <li>YaÄŸÄ±ÅŸ miktarÄ± genel ihtiyacÄ± karÅŸÄ±lÄ±yor.</li>
          <li>Su tutma kapasitesi uygun.</li>
          <li>Kurak dÃ¶nemlerde ek sulama Ã¶nerilebilir.</li>
        </ul>
      </div>
      <div style='background:white;border-radius:14px;padding:1rem;box-shadow:0 1px 4px rgba(0,0,0,0.1)'>
        <h4 style='color:#16A34A;font-size:1.1rem'>ğŸ§ª Toprak Ã–zellikleri</h4>
        <ul style='margin:0;padding-left:1.2rem'>
          <li>pH seviyesi ideal aralÄ±kta.</li>
          <li>Tuzluluk (ECe) dÃ¼ÅŸÃ¼k, verim engeli yok.</li>
          <li>Drenaj ve doku buÄŸday iÃ§in uygun.</li>
        </ul>
      </div>
      <div style='background:white;border-radius:14px;padding:1rem;box-shadow:0 1px 4px rgba(0,0,0,0.1)'>
        <h4 style='color:#78350F;font-size:1.1rem'>ğŸ§± Arazi & Fiziksel KoÅŸullar</h4>
        <ul style='margin:0;padding-left:1.2rem'>
          <li>RakÄ±m ve eÄŸim uygun sÄ±nÄ±rlar iÃ§inde.</li>
          <li>Gece Ä±ÅŸÄ±ÄŸÄ± seviyesi dÃ¼ÅŸÃ¼k (doÄŸal Ã¼retim ortamÄ±).</li>
          <li>RÃ¼zgar etkisi orta dÃ¼zeyde, problem yaratmaz.</li>
        </ul>
      </div>
    </div>
    """,
        unsafe_allow_html=True,
    )
    
    # --- Ä°ndirilebilir Top10 ---
    st.download_button(
        "ğŸ“¥ Top10'u CSV olarak indir",
        data=top10.to_csv(index=False).encode("utf-8"),
        file_name="verimgoren_top10.csv",
        mime="text/csv",
    )
    
    st.caption("--- Analiz tamamlandÄ± ---")
