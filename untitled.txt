# -*- coding: utf-8 -*-
# ==========================================================
# VerimGÃ¶ren â€” Tek Nokta Analizi (Streamlit UI)
# ==========================================================

import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

import numpy as np
import pandas as pd
import streamlit as st

# --- Harici KÃ¼tÃ¼phane KontrolÃ¼ (Rasterio/Pyodbc hatalarÄ±nÄ± yakalamak iÃ§in) ---
try:
    import rasterio
    RASTERIO_AVAILABLE = True
except ImportError:
    RASTERIO_AVAILABLE = False
try:
    import pyodbc
    PYODBC_AVAILABLE = True
except ImportError:
    PYODBC_AVAILABLE = False
# ---------------------------------------------------------------------------

# ---------------------------
# Sayfa YapÄ±landÄ±rmasÄ±
# ---------------------------
st.set_page_config(
    page_title="VerimGÃ¶ren",
    page_icon="ğŸŒ¾",
    layout="wide",
)

# ---------------------------
# Hafif Stil (Minimal Streamlit/Tailwind benzeri)
# ---------------------------
st.markdown("""
<style>
:root { --ink:#0F172A; --muted:#64748B; --card:#FFFFFF; --line:#E5E7EB; --bg:#F8FAFC; --green:#2E7D32; --teal:#00BFA6; }
body { background: var(--bg); }
.vg-card{background:var(--card);border:1px solid var(--line);border-radius:16px;padding:16px;box-shadow:0 2px 6px rgba(15,23,42,.04)}
.vg-pill{display:inline-block;padding:.25rem .6rem;border:1px solid var(--line);border-radius:999px;background:#fff;font-size:.8rem;margin-right:.35rem}
.vg-kpi{display:flex;flex-direction:column;gap:.25rem;border:1px solid var(--line);border-radius:14px;padding:12px;background:#fff}
.vg-kpi .h{color:var(--muted);font-size:.82rem}
.vg-kpi .v{color:var(--ink);font-weight:700;font-size:1.05rem}
.dataframe th { background:#F1F5F9; }
</style>
""", unsafe_allow_html=True)

# ==========================================================
# 1) CLI FonksiyonlarÄ±nÄ±n Streamlit'e UyarlanmÄ±ÅŸ Versiyonu
# ==========================================================

# ---- 1.1 Konum ayrÄ±ÅŸtÄ±rma ----
DMS_PATTERN = re.compile(r"(?P<deg>\d{1,3})Â°(?P<min>\d{1,2})'(?P<sec>[\d\.]+)\"(?P<hemi>[NSEW])")

def dms_to_decimal(deg: float, minute: float, sec: float, hemi: str) -> float:
    sign = -1 if hemi.upper() in ["S", "W"] else 1
    return sign * (abs(deg) + minute / 60.0 + sec / 3600.0)

def parse_latlon_text(text: str) -> Tuple[float, float]:
    text = text.strip()
    parts = re.split(r"[,\s;]+", text)
    parts = [p for p in parts if p]
    if len(parts) < 2:
        raise ValueError("LÃ¼tfen 'lat,lon' biÃ§iminde iki sayÄ± girin. Ã–rn: 38.946838, 28.080573")
    lat = float(parts[0]); lon = float(parts[1])
    if not (-90.0 <= lat <= 90.0 and -180.0 <= lon <= 180.0):
        raise ValueError("GeÃ§ersiz aralÄ±k: enlem [-90,90], boylam [-180,180].")
    return lat, lon

def parse_google_maps_link(text: str) -> Optional[Tuple[float, float]]:
    text = text.strip()
    if "@" in text:
        try:
            after = text.split("@", 1)[1]
            nums = re.split(r"[^-\d\.]+", after)
            nums = [n for n in nums if n]
            lat = float(nums[0]); lon = float(nums[1])
            return lat, lon
        except Exception:
            pass
    dms_hits = DMS_PATTERN.findall(text)
    if len(dms_hits) >= 2:
        (ld, lm, ls, lh), (od, om, os, oh) = dms_hits[0], dms_hits[1]
        lat = dms_to_decimal(float(ld), float(lm), float(ls), lh)
        lon = dms_to_decimal(float(od), float(om), float(os), oh)
        return lat, lon
    return None

def parse_any_location(text: str) -> Tuple[float, float]:
    link = parse_google_maps_link(text)
    if link is not None:
        return link
    return parse_latlon_text(text)

# ---- 1.2 DeÄŸiÅŸken meta & kategoriler (CLI'dan kopyalandÄ±) ----
CATEGORY_ORDER = ["Konum", "Ä°klim", "Arazi", "Gece IÅŸÄ±ÄŸÄ±", "Toprak", "Ã–zet"]

def category_of(key: str) -> str:
    k = key.upper()
    if k in {"USER_LAT","USER_LON","GRID_LAT","GRID_LON","LATITUDE","LONGITUDE"}: return "Konum"
    if k in {"ELEVATION_M"}: return "Arazi"
    if k in {"NIGHT_LIGHT"}: return "Gece IÅŸÄ±ÄŸÄ±"
    if ("_GRP" in k) or k in {
        "T2M","T2M_MAX","T2M_MIN","T2M_RANGE","T2MDEW","T2MWET","RH2M","QV2M","TQV","PS","SLP",
        "WS2M","WS2M_MAX","WD2M","PRECTOTCORR","TS","TO3","ALLSKY_SFC_SW_DWN","ALLSKY_SFC_PAR_TOT",
        "CLRSKY_SFC_SW_DWN","CLOUD_AMT","CLOUD_AMT_DAY","CLOUD_AMT_NIGHT","CLRSKY_DAYS","DISTANCE_KM"
    }:
        return "Ä°klim"
    if k in {
        "FAO90_DESC","T_USDA_TEX_DESC","S_USDA_TEX_DESC","T_TEXTURE_DESC",
        "T_SAND","T_SILT","T_CLAY","S_SAND","S_SILT","S_CLAY",
        "T_PH_H2O","S_PH_H2O","T_OC","S_OC","T_CEC_SOIL","S_CEC_SOIL",
        "T_CEC_CLAY","S_CEC_CLAY","T_BS","S_BS","T_TEB","S_TEB",
        "T_CACO3","S_CACO3","T_ECE","S_ECE","T_ESP","S_ESP",
        "AWC_MM_PER_M","DRAINAGE_DESC","MU_GLOBAL"
    }:
        return "Toprak"
    if k in {"DISTANCE_KM"}: return "Ã–zet"
    return "Ã–zet"

VAR_META: Dict[str, Dict[str, str]] = {
    # CLI'dan kopyalandÄ±
    "USER_LAT":{"title_tr":"KullanÄ±cÄ± enlem","unit":"Â°"}, "USER_LON":{"title_tr":"KullanÄ±cÄ± boylam","unit":"Â°"},
    "GRID_LAT":{"title_tr":"Ä°klim hÃ¼cresi enlem","unit":"Â°"}, "GRID_LON":{"title_tr":"Ä°klim hÃ¼cresi boylam","unit":"Â°"},
    "LATITUDE":{"title_tr":"Enlem","unit":"Â°"}, "LONGITUDE":{"title_tr":"Boylam","unit":"Â°"},
    "ALLSKY_SFC_PAR_TOT":{"title_tr":"PAR (tÃ¼mÃ¼)","unit":"MJ/mÂ²/gÃ¼n"},
    "ALLSKY_SFC_SW_DWN":{"title_tr":"KÄ±sa dalga (tÃ¼mÃ¼)","unit":"kWh/mÂ²/gÃ¼n"},
    "CLRSKY_SFC_SW_DWN":{"title_tr":"KÄ±sa dalga (aÃ§Ä±k gÃ¶k)","unit":"kWh/mÂ²/gÃ¼n"},
    "CLRSKY_DAYS":{"title_tr":"AÃ§Ä±k gÃ¼n sayÄ±sÄ±","unit":"gÃ¼n/ay"},
    "CLOUD_AMT":{"title_tr":"Bulutluluk","unit":"%"}, "CLOUD_AMT_DAY":{"title_tr":"Bulutluluk (gÃ¼ndÃ¼z)","unit":"%"},
    "CLOUD_AMT_NIGHT":{"title_tr":"Bulutluluk (gece)","unit":"%"}, "QV2M":{"title_tr":"Ã–zgÃ¼l nem (2 m)","unit":"g/kg"},
    "RH2M":{"title_tr":"BaÄŸÄ±l nem (2 m)","unit":"%"}, "T2M":{"title_tr":"SÄ±caklÄ±k (2 m, ort.)","unit":"Â°C"},
    "T2M_MAX":{"title_tr":"Maks. sÄ±caklÄ±k","unit":"Â°C"}, "T2M_MIN":{"title_tr":"Min. sÄ±caklÄ±k","unit":"Â°C"},
    "T2M_RANGE":{"title_tr":"GÃ¼nlÃ¼k sÄ±caklÄ±k aralÄ±ÄŸÄ±","unit":"Â°C"}, "T2MDEW":{"title_tr":"Ã‡iy noktasÄ±","unit":"Â°C"},
    "T2MWET":{"title_tr":"YaÅŸ termometre","unit":"Â°C"}, "TQV":{"title_tr":"Kolon su buharÄ±","unit":"kg/mÂ²"},
    "PS":{"title_tr":"YÃ¼zey basÄ±ncÄ±","unit":"kPa"}, "SLP":{"title_tr":"Denize indirgenmiÅŸ basÄ±nÃ§","unit":"kPa"},
    "WD2M":{"title_tr":"RÃ¼zgar yÃ¶nÃ¼ (2 m)","unit":"Â°"}, "WS2M":{"title_tr":"RÃ¼zgar hÄ±zÄ± (2 m)","unit":"m/s"},
    "WS2M_MAX":{"title_tr":"Maks. rÃ¼zgar (2 m)","unit":"m/s"},
    "PRECTOTCORR":{"title_tr":"Toplam yaÄŸÄ±ÅŸ (dÃ¼z.)","unit":"mm/gÃ¼n"}, "TO3":{"title_tr":"Toplam ozon","unit":"DU"},
    "TS":{"title_tr":"YÃ¼zey sÄ±caklÄ±ÄŸÄ±","unit":"Â°C"}, "DISTANCE_KM":{"title_tr":"UzaklÄ±k (iklim pikseli)","unit":"km"},
    "ELEVATION_M":{"title_tr":"RakÄ±m","unit":"m"}, "NIGHT_LIGHT":{"title_tr":"Gece Ä±ÅŸÄ±ÄŸÄ±","unit":"-"},
    "FAO90_DESC":{"title_tr":"FAO-90 sÄ±nÄ±fÄ±","unit":"-"}, "T_USDA_TEX_DESC":{"title_tr":"USDA doku (Ã¼st)","unit":"-"},
    "S_USDA_TEX_DESC":{"title_tr":"USDA doku (alt)","unit":"-"}, "T_TEXTURE_DESC":{"title_tr":"Ãœst doku (coarse/medium/fine)","unit":"-"},
    "T_SAND":{"title_tr":"Kum (Ã¼st)","unit":"%"}, "T_SILT":{"title_tr":"Silt (Ã¼st)","unit":"%"},
    "T_CLAY":{"title_tr":"Kil (Ã¼st)","unit":"%"}, "S_SAND":{"title_tr":"Kum (alt)","unit":"%"},
    "S_SILT":{"title_tr":"Silt (alt)","unit":"%"}, "S_CLAY":{"title_tr":"Kil (alt)","unit":"%"},
    "T_PH_H2O":{"title_tr":"pH (Ã¼st)","unit":"-"}, "S_PH_H2O":{"title_tr":"pH (alt)","unit":"-"},
    "T_OC":{"title_tr":"Organik C (Ã¼st)","unit":"%"}, "S_OC":{"title_tr":"Organik C (alt)","unit":"%"},
    "T_CEC_SOIL":{"title_tr":"CEC (Ã¼st)","unit":"cmol(+)/kg"}, "S_CEC_SOIL":{"title_tr":"CEC (alt)","unit":"cmol(+)/kg"},
    "T_CEC_CLAY":{"title_tr":"CEC (kil, Ã¼st)","unit":"cmol(+)/kg"}, "S_CEC_CLAY":{"title_tr":"CEC (kil, alt)","unit":"cmol(+)/kg"},
    "T_BS":{"title_tr":"Baz doygunluÄŸu (Ã¼st)","unit":"%"}, "S_BS":{"title_tr":"Baz doygunluÄŸu (alt)","unit":"%"},
    "T_TEB":{"title_tr":"Toplam deÄŸiÅŸebilir baz (Ã¼st)","unit":"cmol(+)/kg"}, "S_TEB":{"title_tr":"Toplam deÄŸiÅŸebilir baz (alt)","unit":"cmol(+)/kg"},
    "T_CACO3":{"title_tr":"KireÃ§ CaCO3 (Ã¼st)","unit":"%"}, "S_CACO3":{"title_tr":"KireÃ§ CaCO3 (alt)","unit":"%"},
    "T_ECE":{"title_tr":"EC (Ã¼st)","unit":"dS/m"}, "S_ECE":{"title_tr":"EC (alt)","unit":"dS/m"},
    "T_ESP":{"title_tr":"ESP (Ã¼st)","unit":"%"}, "S_ESP":{"title_tr":"ESP (alt)","unit":"%"},
    "AWC_MM_PER_M":{"title_tr":"KullanÄ±labilir su (AWC)","unit":"mm/m"}, "DRAINAGE_DESC":{"title_tr":"Drenaj","unit":"-"},
    "MU_GLOBAL":{"title_tr":"Harita birimi (MU)","unit":"-"},
}

def meta_of(key: str):
    base = key.replace("_grp1","").replace("_grp2","").replace("_grp3","").replace("_grp4","")
    m = VAR_META.get(key) or VAR_META.get(base.upper()) or VAR_META.get(base)
    if m: return m["title_tr"], m.get("unit","-")
    return base, "-"

def format_value(v):
    if v is None or (isinstance(v, float) and (np.isnan(v) or np.isinf(v))): return "-"
    try:
        f = float(v)
        if abs(f - round(f)) < 1e-9: return f"{int(round(f))}"
        return f"{f:.2f}"
    except Exception:
        return str(v)

# ---- 1.3 Veri kaynaklarÄ± (CLI'dan kopyalandÄ±) ----
def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1; dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2
    return 2 * R * np.arcsin(np.sqrt(a))

@st.cache_data(show_spinner=False)
def load_climate_nearest(csv_path: Path, lat: float, lon: float) -> dict:
    if not csv_path.exists():
        # Bu hata Streamlit tarafÄ±ndan yakalanacaktÄ±r.
        raise FileNotFoundError(f"Ä°klim CSV bulunamadÄ±: {csv_path}")
    df = pd.read_csv(csv_path)
    if not {"latitude","longitude"}.issubset(df.columns):
        raise ValueError("Ä°klim CSVâ€™de 'latitude' ve 'longitude' sÃ¼tunlarÄ± yok.")
    dist = haversine(lat, lon, df["latitude"].values, df["longitude"].values)
    i = int(np.argmin(dist))
    row = df.iloc[i].to_dict()
    row["DISTANCE_KM"] = float(dist[i])
    return row

def sample_raster(path: Path, lon: float, lat: float):
    if not RASTERIO_AVAILABLE:
        # st.toast("UyarÄ±: 'rasterio' kurulu deÄŸil. RakÄ±m/IÅŸÄ±k verisi atlanÄ±yor.", icon="âš ï¸")
        return None
    try:
        if not path.exists(): return None
        with rasterio.open(path) as ds:
            r, c = ds.index(lon, lat)
            val = ds.read(1)[r, c]
            if ds.nodata is not None and val == ds.nodata: return None
            return float(val)
    except Exception:
        return None

def load_soil_env(lat: float, lon: float, HWSD_MDB: Path, HWSD_RAS: Path) -> Optional[dict]:
    if not RASTERIO_AVAILABLE or not PYODBC_AVAILABLE:
        # st.toast("UyarÄ±: 'rasterio' veya 'pyodbc' eksik. Toprak verisi atlanÄ±yor.", icon="âš ï¸")
        return None
        
    if not HWSD_MDB.exists() or not HWSD_RAS.exists():
        return None

    try:
        # MU_GLOBAL bul (rasterio gerektirir)
        with rasterio.open(HWSD_RAS) as src:
            r, c = src.index(lon, lat)
            mu = int(src.read(1)[r, c])
        if mu <= 0:
            return None
    except Exception:
        return None

    # Access tablolar
    def _read(table):
        # NOT: pyodbc'nin dÃ¼zgÃ¼n Ã§alÄ±ÅŸmasÄ± iÃ§in sistemde Access veritabanÄ± sÃ¼rÃ¼cÃ¼sÃ¼ olmalÄ±dÄ±r.
        cn = pyodbc.connect(f"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={str(HWSD_MDB).replace('\\','/')};")
        try:
            return pd.read_sql(f"SELECT * FROM {table}", cn)
        finally:
            cn.close()

    def _norm(df):
        df = df.copy(); df.columns = [c.strip().upper() for c in df.columns]; return df

    try:
        hwsd = _norm(_read("HWSD_DATA"))
    except Exception:
        return None

    # lookuplar ve merge iÅŸlemi (CLI'dan kopyalandÄ±)
    def _lut(df, out_code, out_desc):
        if df is None: return None
        cols = set(df.columns)
        code = "CODE" if "CODE" in cols else None
        desc = "DESCRIPTION" if "DESCRIPTION" in cols else ("VALUE" if "VALUE" in cols else None)
        if code and desc:
            return df.rename(columns={code:out_code, desc:out_desc})[[out_code,out_desc]]
        return None

    def _safe(name):
        try: return _norm(_read(name))
        except Exception: return None

    tex = _lut(_safe("D_TEXTURE"), "T_TEXTURE", "T_TEXTURE_DESC")
    utexT = _lut(_safe("D_USDA_TEX_CLASS"), "T_USDA_TEX_CLASS", "T_USDA_TEX_DESC")
    utexS = _lut(_safe("D_USDA_TEX_CLASS"), "S_USDA_TEX_CLASS", "S_USDA_TEX_DESC")
    awc = _lut(_safe("D_AWC"), "AWC_CLASS", "AWC_MM_PER_M")
    drn = _lut(_safe("D_DRAINAGE"), "DRAINAGE", "DRAINAGE_DESC")
    sym90 = _lut(_safe("D_SYMBOL90"), "SU_CODE90", "FAO90_DESC")

    df = hwsd
    for cond, lut, key in [
        ("T_TEXTURE", tex, "T_TEXTURE"),
        ("T_USDA_TEX_CLASS", utexT, "T_USDA_TEX_CLASS"),
        ("S_USDA_TEX_CLASS", utexS, "S_USDA_TEX_CLASS"),
        ("AWC_CLASS", awc, "AWC_CLASS"),
        ("DRAINAGE", drn, "DRAINAGE"),
        ("SU_CODE90", sym90, "SU_CODE90"),
    ]:
        if (cond in df.columns) and (lut is not None):
            df = df.merge(lut, on=key, how="left")

    num_cols = [
        "AWC_MM_PER_M","T_PH_H2O","S_PH_H2O","T_OC","S_OC",
        "T_CLAY","T_SILT","T_SAND","S_CLAY","S_SILT","S_SAND",
        "T_ECE","S_ECE","T_ESP","S_ESP","T_CEC_SOIL","S_CEC_SOIL",
        "T_CEC_CLAY","S_CEC_CLAY","T_BS","S_BS","T_TEB","S_TEB","T_CACO3","S_CACO3",
    ]
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c].astype(str).str.replace(",", "."), errors="coerce")

    # dominant bileÅŸen (SEQ, SHARE)
    if not {"MU_GLOBAL","SEQ","SHARE"}.issubset(df.columns):
        return None
    dom = (df.sort_values(["MU_GLOBAL","SEQ","SHARE"], ascending=[True,True,False])
              .groupby("MU_GLOBAL", as_index=False).first())
    row = dom.loc[dom["MU_GLOBAL"]==mu]
    if row.empty: return None
    return row.iloc[0].to_dict()

# ---- 1.4 Skor modÃ¼lÃ¼ (CLI'dan kopyalandÄ± ve rad_max=3.2 fix eklendi) ----
def _clip01(x): x=float(x); return 0.0 if x<0 else (1.0 if x>1 else x)
def _presence(val): return (val is not None) and (str(val).strip() != "")
def _mean_safe(vals): vals=[float(v) for v in vals if _presence(v)]; return sum(vals)/len(vals) if vals else None
def _trapezoid_score(x,a,b,c,d):
    if any(v is None for v in [x,a,b,c,d]): return None
    x=float(x); a,b,c,d = float(a),float(b),float(c),float(d)
    if a>=b or b>c or c>=d: return None
    if x<=a or x>=d: return 0.0
    if b<=x<=c: return 100.0
    if a<x<b: return 100.0*(x-a)/(b-a)
    return 100.0*(d-x)/(d-c)

def suitability_score(crop, env, weights=None, params=None):
    W={'thermal':12,'frost':6,'heat':6,'rad':8,'rh':8,'water':15,'ph':8,'ec':8,'soilphys':5,'taw':4,'esp':3,'caco3':3,'cec':2,'elev':5,'wind':3,'night':2}
    if isinstance(weights, dict): W.update(weights)
    # CLI'daki rad_max dÃ¼zeltmesi uygulandÄ± (2.8 -> 3.2)
    P={'rh_opt':60.0,'rh_span':30.0,'rad_min':1.2,'rad_max':3.2,'frost_band':5.0,'heat_band':5.0,'taw_ref_default':120.0}

    modules, usedW = {}, {}
    Tavg=env.get('T2M_grp2'); Tmin=env.get('T2M_MIN_grp2'); Tmax=env.get('T2M_MAX_grp2')
    tmin_abs=crop.get('tmin_abs'); topt_min=crop.get('topt_min'); topt_max=crop.get('topt_max'); tmax_abs=crop.get('tmax_abs')

    if all(_presence(v) for v in [Tavg,tmin_abs,topt_min,topt_max,tmax_abs]):
        modules['thermal']=_trapezoid_score(Tavg,tmin_abs,topt_min,topt_max,tmax_abs); usedW['thermal']=W['thermal']
    if all(_presence(v) for v in [Tmin,tmin_abs]):
        modules['frost']=100.0 if float(Tmin)>=float(tmin_abs) else max(0.0, 100.0-100.0*(abs(float(tmin_abs)-float(Tmin))/P['frost_band'])); usedW['frost']=W['frost']
    if all(_presence(v) for v in [Tmax,tmax_abs]):
        modules['heat']=100.0 if float(Tmax)<=float(tmax_abs) else max(0.0, 100.0-100.0*(abs(float(Tmax)-float(tmax_abs))/P['heat_band'])); usedW['heat']=W['heat']

    R=env.get('ALLSKY_SFC_SW_DWN_grp1')
    if _presence(R):
        modules['rad']=100.0*_clip01((float(R)-P['rad_min'])/max(1e-6,(P['rad_max']-P['rad_min']))); usedW['rad']=W['rad']
    RH=env.get('RH2M_grp2')
    if _presence(RH):
        modules['rh']=100.0*_clip01(1.0-((float(RH)-P['rh_opt'])/P['rh_span'])**2); usedW['rh']=W['rh']

    Pmm=env.get('PRECTOTCORR_grp4'); kc_avg=_mean_safe([crop.get('kc_initial'),crop.get('kc_mid'),crop.get('kc_end')])
    ETc=env.get('ETc'); ET0=env.get('ET0'); AWC=env.get('AWC_MM_PER_M'); Zr=crop.get('root_depth_m')
    if _presence(Pmm) and _presence(kc_avg) and (_presence(ETc) or _presence(ET0)) and _presence(Zr):
        if not _presence(ETc): ETc=float(ET0)*float(kc_avg)
        deficit=max(0.0, float(ETc)-float(Pmm))
        
        # EÄŸer AWC eksik deÄŸilse (Toprak verisi geldiyse), su modÃ¼lÃ¼nÃ¼ hesapla
        if _presence(AWC):
            TAW=float(AWC)*float(Zr); denom=max(1.0, TAW/15.0)
            modules['water']=100.0*_clip01(1.0-deficit/denom); usedW['water']=W['water']

    soil_pH=env.get('T_PH_H2O'); pH_min=crop.get('pH_min'); pH_max=crop.get('pH_max')
    if all(_presence(v) for v in [soil_pH,pH_min,pH_max]):
        a=float(pH_min)-0.5; b=float(pH_min); c=float(pH_max); d=float(pH_max)+0.5
        modules['ph']=_trapezoid_score(float(soil_pH),a,b,c,d); usedW['ph']=W['ph']

    soil_EC=env.get('T_ECE'); ec_thr = crop.get('ece_threshold_dSm') if 'ece_threshold_dSm' in crop else crop.get('ece_threshold_dsm')
    if all(_presence(v) for v in [soil_EC,ec_thr]):
        thr=max(0.1,float(ec_thr)); modules['ec']=100.0*_clip01(1.0-float(soil_EC)/thr); usedW['ec']=W['ec']

    tex_ok=(crop.get('texture_ok') or "").lower().replace(" ","")
    tex_ok_set=set([t.strip().lower() for t in tex_ok.split(",") if t.strip()])
    tex_env=(env.get('T_USDA_TEX_DESC') or "").strip().lower().replace(" ","")
    drain_pref=(crop.get('drainage_preference') or "").strip().lower()
    drain_env =(env.get('DRAINAGE_DESC') or "").strip().lower()

    score_tex=None
    if tex_env:
        if tex_env in tex_ok_set: score_tex=100.0
        else:
            neigh={'loam':{'sandy_loam','silt_loam','clay_loam'},'sandy_loam':{'loam'},'silt_loam':{'loam'},'clay_loam':{'loam'},
                   'sandy_clay_loam':{'clay_loam','sandy_loam'},'silty_clay_loam':{'clay_loam','silt_loam'}}
            score_tex=60.0 if any((k in tex_ok_set and tex_env in neigh.get(k,set())) for k in tex_ok_set) else 0.0

    def _norm_drain(s):
        s=s.lower()
        if 'well' in s and 'moderate' not in s: return 'well'
        if 'moderately' in s: return 'moderately well'
        if 'very poorly' in s: return 'very poorly'
        if 'poorly' in s: return 'poorly'
        if 'somewhat' in s: return 'somewhat poorly'
        return None

    score_drain=None
    if drain_pref and drain_env:
        dkey=_norm_drain(drain_env); dmap={'well':100,'moderately well':70,'somewhat poorly':40,'poorly':0,'very poorly':0}
        score_drain=dmap.get(dkey,70.0)

    if score_tex is not None or score_drain is not None:
        parts,wsum=[],0.0
        if score_tex is not None: parts.append((score_tex,0.6)); wsum+=0.6
        if score_drain is not None: parts.append((score_drain,0.4)); wsum+=0.4
        modules['soilphys']=sum(s*w for s,w in parts)/(wsum if wsum else 1.0); usedW['soilphys']=W['soilphys']

    if _presence(AWC) and _presence(Zr):
        TAW=float(AWC)*float(Zr); ref=float((params or {}).get('taw_ref_default',120.0))
        modules['taw']=100.0*_clip01(TAW/ref); usedW['taw']=W['taw']

    ESP=env.get('T_ESP') or env.get('ESP')
    if _presence(ESP):
        modules['esp']=100.0*_clip01(1.0-float(ESP)/8.0); usedW['esp']=W['esp']

    CACO3=env.get('T_CACO3') or env.get('S_CACO3') or env.get('CACO3')
    if _presence(CACO3):
        modules['caco3']=100.0*_clip01(1.0-float(CACO3)/10.0); usedW['caco3']=W['caco3']

    CEC=env.get('T_CEC_SOIL')
    if _presence(CEC):
        CEC=float(CEC); modules['cec']=40.0 if CEC<8.0 else (70.0 if CEC<12.0 else 100.0); usedW['cec']=W['cec']

    elev=env.get('ELEVATION_M'); elev_min=crop.get('elevation_min'); elev_max=crop.get('elevation_max')
    if _presence(elev):
        e=float(elev)
        if _presence(elev_min) and _presence(elev_max):
            a=float(elev_min)-200.0; b=float(elev_min); c=float(elev_max); d=float(elev_max)+200.0
            modules['elev']=_trapezoid_score(e,a,b,c,d)
        else:
            modules['elev']=100.0 if e<1500 else (70.0 if e<2000 else (40.0 if e<2500 else 0.0))
        usedW['elev']=W['elev']

    WSMAX=env.get('WS2M_MAX_grp3')
    if _presence(WSMAX):
        modules['wind']=100.0*_clip01(1.0-float(WSMAX)/15.0); usedW['wind']=W['wind']

    NL=env.get('NIGHT_LIGHT')
    if _presence(NL):
        modules['night']=100.0*_clip01(1.0-float(NL)/5.0); usedW['night']=W['night'] # 1.0 - NL/5.0
        
    if not usedW: return {'score': None, 'modules': modules, 'used_weights': usedW}
    wsum=float(sum(usedW.values())); total=0.0
    for k, sc in modules.items():
        if sc is None: continue
        wk=usedW.get(k,0.0)/wsum; total += wk*float(sc)
    return {'score': round(total,2), 'modules': {k:round(v,2) for k,v in modules.items()}, 'used_weights': usedW}

@st.cache_data(show_spinner=False)
def load_crops(crops_csv_path: Path) -> pd.DataFrame:
    if not crops_csv_path.exists():
        raise FileNotFoundError(f"Bitki CSV bulunamadÄ±: {crops_csv_path}")
    df = pd.read_csv(crops_csv_path)
    df.columns = [c.strip().lower() for c in df.columns]
    return df

def row_to_crop_dict(row: pd.Series) -> dict:
    d = row.to_dict()
    if 'ece_threshold_dsm' in d and 'ece_threshold_dSm' not in d:
        d['ece_threshold_dSm'] = d['ece_threshold_dsm']
    if not str(d.get('texture_ok','')).strip():
        d['texture_ok'] = ''
    return d

def weakest_modules(mod_dict, n=2):
    if not mod_dict: return []
    items = [(k,v) for k,v in mod_dict.items() if v is not None]
    if not items: return []
    items.sort(key=lambda x: x[1])
    return [f"{k}:{v:.0f}" for k,v in items[:n]]

def build_env(lat: float, lon: float,
              CLIMATE_CSV: Path,
              ELEV_TIF: Optional[Path]=None,
              LIGHT_TIF: Optional[Path]=None,
              HWSD_MDB: Optional[Path]=None,
              HWSD_RAS: Optional[Path]=None) -> dict:
    env = {}
    env["USER_LAT"] = float(lat); env["USER_LON"] = float(lon)

    clim = load_climate_nearest(CLIMATE_CSV, lat, lon)
    env.update(clim)
    if "latitude" in clim and "longitude" in clim:
        env["GRID_LAT"] = float(clim["latitude"])
        env["GRID_LON"] = float(clim["longitude"])

    # Raster Verileri
    if ELEV_TIF and ELEV_TIF.exists():
        elev = sample_raster(ELEV_TIF, lon, lat)
        if elev is not None: env["ELEVATION_M"] = elev
    if LIGHT_TIF and LIGHT_TIF.exists():
        night = sample_raster(LIGHT_TIF, lon, lat)
        if night is not None: env["NIGHT_LIGHT"] = night

    # HWSD Verileri
    if HWSD_MDB and HWSD_RAS and HWSD_MDB.exists() and HWSD_RAS.exists():
        soil = load_soil_env(lat, lon, HWSD_MDB, HWSD_RAS)
        if soil: env.update(soil)

    # Alias (skor modÃ¼lÃ¼yle uyum)
    def _pick(d,*keys):
        for k in keys:
            if k in d: return d[k]
        return None
    env['T2M_grp2'] = _pick(env,'T2M_grp2','T2M_GRP2','T2M')
    env['T2M_MIN_grp2'] = _pick(env,'T2M_MIN_grp2','T2M_MIN_GRP2','T2M_MIN')
    env['T2M_MAX_grp2'] = _pick(env,'T2M_MAX_grp2','T2M_MAX_GRP2','T2M_MAX')
    env['RH2M_grp2'] = _pick(env,'RH2M_grp2','RH2M_GRP2','RH2M')
    env['ALLSKY_SFC_SW_DWN_grp1'] = _pick(env,'ALLSKY_SFC_SW_DWN_grp1','ALLSKY_SFC_SW_DWN_GRP1','ALLSKY_SFC_SW_DWN')
    env['PRECTOTCORR_grp4'] = _pick(env,'PRECTOTCORR_grp4','PRECTOTCORR_GRP4','PRECTOTCORR')
    env['WS2M_MAX_grp3'] = _pick(env,'WS2M_MAX_grp3','WS2M_MAX_GRP3','WS2M_MAX')
    return env

def score_and_rank_df(env: dict, crops_df: pd.DataFrame) -> pd.DataFrame:
    results = []
    for _, row in crops_df.iterrows():
        crop = row_to_crop_dict(row)
        res = suitability_score(crop, env)
        if res.get('score') is None:
            continue
        results.append({
            'crop': crop.get('crop'),
            'common_name_tr': crop.get('common_name_tr'),
            'score': res['score'],
            'weakest_two': ", ".join(weakest_modules(res.get('modules', {}), n=2)) or "-",
            'modules': res.get('modules', {})
        })
    df = pd.DataFrame(results).sort_values("score", ascending=False).reset_index(drop=True)
    return df

# ==========================================================
# 2) ARAYÃœZ
# ==========================================================

# ---- 2.1 Ãœst baÅŸlÄ±k ----
st.title("ğŸŒ¾ VerimGÃ¶ren: TarÄ±msal Uygunluk Analizi")
st.markdown("---")

# ---- 2.2 Sidebar: Ayarlar/Yollar (Mutlak yollarÄ± manuel girmek zorunludur) ----
with st.sidebar:
    st.header("âš™ï¸ Veri YollarÄ± (Mutlak)")
    st.caption("LÃ¼tfen tÃ¼m dosya yollarÄ±nÄ± (C:/Users/...) girin.")

    # Mutlak yollarÄ± Streamlit'ten alÄ±yoruz
    default_base = r"C:/Users/MEHMET/Desktop/MEHMET/VerimGÃ¶ren"
    
    crops_path_str = st.text_input("CROPS_CSV (Bitkiler - Zorunlu)", 
                                  value=Path(default_base, "notebooks/VerimGoren_Bitki_Parametreleri_Tam.csv").as_posix(),
                                  placeholder=Path(default_base, "notebooks/VerimGoren_Bitki_Parametreleri_Tam.csv").as_posix())
    
    climate_path_str = st.text_input("CLIMATE_CSV (Ä°klim - Zorunlu)", 
                                     value=Path(default_base, "notebooks/data/climate/merged_climate_data.csv").as_posix(),
                                     placeholder=Path(default_base, "notebooks/data/climate/merged_climate_data.csv").as_posix())
    
    st.markdown("---")
    st.caption("Opsiyonel Raster ve Toprak Verileri")
    
    # RakÄ±m ve IÅŸÄ±k
    elev_used = st.checkbox("â›°ï¸ RakÄ±m (ELEV_TIF) kullan", value=True)
    elev_path_str = st.text_input("ELEV_TIF Yolu", 
                                   value=Path(default_base, "data/processed/srtm_turkiye_cropped.tif").as_posix(), 
                                   disabled=not elev_used, 
                                   placeholder=Path(default_base, "data/processed/srtm_turkiye_cropped.tif").as_posix()) if elev_used else ""

    light_used = st.checkbox("ğŸŒƒ Gece IÅŸÄ±ÄŸÄ± (LIGHT_TIF) kullan", value=True)
    light_path_str = st.text_input("LIGHT_TIF Yolu", 
                                    value=Path(default_base, "data/processed/viirs_light_2024_turkey.tif").as_posix(), 
                                    disabled=not light_used, 
                                    placeholder=Path(default_base, "data/processed/viirs_light_2024_turkey.tif").as_posix()) if light_used else ""
    
    # HWSD
    hwsd_used = st.checkbox("ğŸŒ± HWSD Toprak Verisi kullan (MDB + Raster)", value=True)
    if hwsd_used:
        if not RASTERIO_AVAILABLE or not PYODBC_AVAILABLE:
            st.warning("âš ï¸ Rasterio/Pyodbc eksik. Toprak verisi okunamaz.")
            
        mdb_path_str = st.text_input("HWSD_MDB Yolu", 
                                     value=Path(default_base, "notebooks/hwsd_data/HWSD.mdb").as_posix(), 
                                     placeholder=Path(default_base, "notebooks/hwsd_data/HWSD.mdb").as_posix())
        
        ras_path_str = st.text_input("HWSD_RAS Yolu (.bil)", 
                                     value=Path(default_base, "notebooks/hwsd_data/hwsd.bil").as_posix(), 
                                     placeholder=Path(default_base, "notebooks/hwsd_data/hwsd.bil").as_posix())
    else:
        mdb_path_str, ras_path_str = "", ""

    # Path nesnelerini oluÅŸtur
    CROPS_CSV = Path(crops_path_str) if crops_path_str else None
    CLIMATE_CSV = Path(climate_path_str) if climate_path_str else None
    ELEV_TIF = Path(elev_path_str) if elev_path_str else None
    LIGHT_TIF = Path(light_path_str) if light_path_str else None
    HWSD_MDB = Path(mdb_path_str) if mdb_path_str else None
    HWSD_RAS = Path(ras_path_str) if ras_path_str else None

    # Durum KontrolÃ¼
    st.markdown("---")
    st.subheader("âœ… Dosya Durumu")
    
    def _ok(p: Optional[Path]): return p and p.exists()
    
    st.markdown(f"**Bitki CSV**: {'âœ… BULUNDU' if _ok(CROPS_CSV) else 'âŒ YOK'}")
    st.markdown(f"**Ä°klim CSV**: {'âœ… BULUNDU' if _ok(CLIMATE_CSV) else 'âŒ YOK'}")
    
    if elev_used: st.markdown(f"**RakÄ±m TIF**: {'âœ… BULUNDU' if _ok(ELEV_TIF) else 'âŒ YOK'}")
    if light_used: st.markdown(f"**IÅŸÄ±k TIF**: {'âœ… BULUNDU' if _ok(LIGHT_TIF) else 'âŒ YOK'}")
    
    if hwsd_used:
        st.markdown(f"**HWSD MDB**: {'âœ… BULUNDU' if _ok(HWSD_MDB) else 'âŒ YOK'}")
        st.markdown(f"**HWSD RAS**: {'âœ… BULUNDU' if _ok(HWSD_RAS) else 'âŒ YOK'}")

# ---- 2.3 Girdi AlanÄ± ----
g_left, g_right = st.columns([0.5, 0.5])
with g_left:
    st.subheader("ğŸ“ Analiz Konumu")
    loc_str = st.text_input("Google Maps linki veya 'lat,lon'", 
                            value="38.554205, 38.707944", 
                            placeholder="38.554205, 38.707944")
    run = st.button("Raporu OluÅŸtur", type="primary")

with g_right:
    st.subheader("â„¹ï¸ Ä°puÃ§larÄ± & Durum KontrolÃ¼")
    st.markdown(
        "- **Zorunlu:** Sidebar'dan (solda) `Bitki CSV` ve `Ä°klim CSV` yollarÄ±nÄ±n **`âœ… BULUNDU`** olduÄŸundan emin olun.\n"
        "- **Format:** Konumu `enlem, boylam` veya tam Google Maps linki olarak girin.\n"
        "- **Hata KaynaÄŸÄ±:** EÄŸer skorlama eksikse, `Toprak` ve `Arazi` verilerinin `âŒ YOK` olmasÄ± normaldir (opsiyoneldirler)."
    )

st.write("")

# ==========================================================
# 3) HESAPLAMA & SUNUM
# ==========================================================
if run:
    # Zorunlu dosyalar kontrol
    if not CROPS_CSV or not CLIMATE_CSV or not CROPS_CSV.exists() or not CLIMATE_CSV.exists():
        st.error("Zorunlu dosyalar (Bitki ve Ä°klim CSV) eksik veya yanlÄ±ÅŸ yol girildi. Soldaki yollarÄ± doÄŸrulayÄ±n.")
        st.stop()

    # Konum ayrÄ±ÅŸtÄ±r
    try:
        lat, lon = parse_any_location(loc_str)
    except Exception as e:
        st.error(f"Konum Ã§Ã¶zÃ¼mlenemedi: {e}")
        st.stop()

    with st.spinner("Ã‡evre verileri toplanÄ±yor..."):
        try:
            env = build_env(lat, lon, CLIMATE_CSV, ELEV_TIF, LIGHT_TIF, HWSD_MDB, HWSD_RAS)
        except Exception as e:
            st.error(f"Veri Toplama HatasÄ± ({type(e).__name__}): {e}")
            st.caption("LÃ¼tfen console loglarÄ±nÄ± kontrol edin (pyodbc/rasterio hatalarÄ± olabilir).")
            st.stop()

    # ---- 3.1 Ã–zet baÅŸlÄ±ÄŸÄ±
    st.success(f"ğŸ“ Konum Analiz BaÅŸarÄ±lÄ±! Enlem: {lat:.5f}, Boylam: {lon:.5f}Â  |Â  Ä°klim Piks. UzaklÄ±k: {format_value(env.get('DISTANCE_KM'))} km")
    
    # Harita gÃ¶rselleÅŸtirmesi ekleyelim
    st.map(pd.DataFrame({'lat': [lat], 'lon': [lon]}), zoom=9)

    # ---- 3.2 KPI kartlarÄ±
    st.subheader("Ã‡evresel KoÅŸullar Ã–zeti")
    k1, k2, k3, k4, k5, k6 = st.columns(6)
    with k1:
        st.markdown(f'<div class="vg-kpi"><div class="h">Ort. SÄ±caklÄ±k (Â°C)</div><div class="v">{format_value(env.get("T2M_grp2"))}</div></div>', unsafe_allow_html=True)
    with k2:
        st.markdown(f'<div class="vg-kpi"><div class="h">YaÄŸÄ±ÅŸ (mm/gÃ¼n)</div><div class="v">{format_value(env.get("PRECTOTCORR_grp4"))}</div></div>', unsafe_allow_html=True)
    with k3:
        st.markdown(f'<div class="vg-kpi"><div class="h">Radyasyon (kWh/mÂ²/g)</div><div class="v">{format_value(env.get("ALLSKY_SFC_SW_DWN_grp1"))}</div></div>', unsafe_allow_html=True)
    with k4:
        st.markdown(f'<div class="vg-kpi"><div class="h">RakÄ±m (m)</div><div class="v">{format_value(env.get("ELEVATION_M"))}</div></div>', unsafe_allow_html=True)
    with k5:
        st.markdown(f'<div class="vg-kpi"><div class="h">pH (Ã¼st katman)</div><div class="v">{format_value(env.get("T_PH_H2O"))}</div></div>', unsafe_allow_html=True)
    with k6:
        st.markdown(f'<div class="vg-kpi"><div class="h">ECe (Tuzluluk, dS/m)</div><div class="v">{format_value(env.get("T_ECE"))}</div></div>', unsafe_allow_html=True)

    st.write("")

    # ---- 3.3 Kategorize edilmiÅŸ Ã§evre tablosu
    with st.expander("ğŸ§¾ TÃ¼m Ã‡evre DeÄŸiÅŸkenleri (DetaylÄ± Rapor)", expanded=False):
        rows = []
        for k, v in env.items():
            if k in {"latitude","longitude","USER_LAT","USER_LON","GRID_LAT","GRID_LON", "DISTANCE_KM"}: continue
            
            # Grubu kaldÄ±rÄ±lmÄ±ÅŸ anahtarÄ± bul
            base_k = k.split('_grp')[0]
            if base_k.upper() not in VAR_META and base_k.upper() not in env:
                 continue

            cat = category_of(k)
            title, unit = meta_of(k)
            
            # CLRSKY_DAYS birimi dÃ¼zeltmesi
            if k.startswith("CLRSKY_DAYS"):
                 if isinstance(v,(int,float)) and float(v) > 31:
                     unit = "gÃ¼n/yÄ±l"

            rows.append({
                "Kategori": cat,
                "BaÅŸlÄ±k": title,
                "DeÄŸer": format_value(v) if v is not None else "(Veri Eksik)",
                "Birim": unit if unit != "-" else ""
            })
        
        env_df = pd.DataFrame(rows)
        # SÃ¼tunlarÄ± yeniden sÄ±rala
        env_df = env_df[["Kategori", "BaÅŸlÄ±k", "DeÄŸer", "Birim"]]
        
        # Kategorilere gÃ¶re sÄ±rala
        cat_map = {cat: i for i, cat in enumerate(CATEGORY_ORDER)}
        env_df['Kategori_Sort'] = env_df['Kategori'].map(cat_map)
        env_df = env_df.sort_values(by=['Kategori_Sort', 'BaÅŸlÄ±k']).drop(columns=['Kategori_Sort'])

        st.dataframe(env_df, use_container_width=True, height=360, hide_index=True)


    # ---- 3.4 Skorlama
    st.write("")
    st.subheader("ğŸŒ± ÃœrÃ¼n Uygunluk SÄ±ralamasÄ± (0â€“100)")
    try:
        crops_df = load_crops(CROPS_CSV)
        results_df = score_and_rank_df(env, crops_df)
    except Exception as e:
        st.error(f"Bitki Skorlama HatasÄ±: {type(e).__name__}: {e}")
        st.stop()

    if results_df.empty:
        st.warning("Skor Ã¼retilemedi â€” gerekli Ã§evre/bitki alanlarÄ± eksik olabilir. LÃ¼tfen console loglarÄ±nÄ± kontrol edin.")
    else:
        # Filtreler
        fcol1, fcol2 = st.columns([1,2])
        with fcol1:
            min_score = st.slider("Minimum skor", 0, 100, 70, 1)
        with fcol2:
            name_filter = st.text_input("ÃœrÃ¼n adÄ± filtre", value="")

        filtered = results_df.copy()
        if min_score > 0:
            filtered = filtered[filtered["score"] >= min_score]
        if name_filter.strip():
            s = name_filter.strip().lower()
            filtered = filtered[filtered["common_name_tr"].fillna("").str.lower().str.contains(s) | 
                                filtered["crop"].fillna("").str.lower().str.contains(s)]

        # GÃ¶rÃ¼nÃ¼r tablo (modules kolonunu gizle)
        view_df = filtered[["common_name_tr", "crop", "score", "weakest_two"]].rename(columns={
            "common_name_tr":"TÃ¼rkÃ§e Ad",
            "crop":"Kod (Ä°ng.)",
            "score":"Uygunluk Skoru",
            "weakest_two":"Neyi KÄ±sÄ±tlÄ±yor? (En ZayÄ±f 2 ModÃ¼l)"
        })
        
        # Stil ekle (Skora gÃ¶re renk)
        def color_score(val):
            color = 'background-color: #F8D7DA' if val < 50 else ('background-color: #FFF3CD' if val < 75 else 'background-color: #D4EDDA')
            return f'{color}; font-weight: bold'

        st.dataframe(view_df.style.applymap(color_score, subset=['Uygunluk Skoru']), 
                     use_container_width=True, 
                     height=420,
                     hide_index=True)

        # Ã–zet/indirme
        if not filtered.empty:
            top3 = filtered.sort_values("score", ascending=False).head(3)["common_name_tr"].fillna(filtered["crop"].head(3)).tolist()
            best = top3[0] if top3 else "-"
            st.info(f"ğŸ† **En uygun Ã¼rÃ¼n**: **{best}** â€” DiÄŸer Ã¶nerilenler: {', '.join(top3[1:])}")

            csv_bytes = filtered.to_csv(index=False).encode("utf-8")
            st.download_button("CSV indir", data=csv_bytes, file_name="verimgoren_skorlar.csv", mime="text/csv")
        else:
            st.warning("SeÃ§ilen minimum skor filtresine uygun Ã¼rÃ¼n bulunamadÄ±.")
            

    st.caption("--- Analiz Bitti ---")